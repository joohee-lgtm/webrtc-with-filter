## 한계점
### (먼저 말하는) 결론
- ios safari
    - webgl 과 getUserDevice 를 이용하면 웹카메라 + realtime filter 를 충분히 구현할 수 있다.
    - video 로 export 하는 것은 native api 로는 불가능하다. websocket 서버를 통해 프레임을 실시간으로 서버로 보내고 video/mp4 포맷의 파일을 서버에서 생성해야 한다.
- android
    - [안드로이드 크롬 52 버전](https://chromereleases.googleblog.com/2016/07/chrome-for-android-update.html) 이상, [삼성 브라우저 6.0](https://www.sammobile.com/apk/samsung-internet-for-android/samsung-internet-browser-6-0-01-10/) 이상의 최신 브라우저에서는 canvas 2d filter, webgl / webrtc getUserDevice, recording 등 모든 API 를 동시에 사용할 수 있다.

### safari 와 recording
- 2017년도 6월에 열린 WWDC 에서 ios11 에서 부터 WebRTC 기술이 탑재된다고 발표된 이래로 `getUserDevice` 와 `RTCPeerConnection` API 외에는 모두 지원하지 않고 있다.
- canvas 를 레코딩 할때 가장 중요하게 사용될 `MediaRecorder` 와 `captureStream` API 에 대해서는 아직 지원 계획을 찾을 수 없다.
    - (이럴거면 webkit 공식 홈페이지에서도 Support 표시는 빼버려야 하는거 아닌가 🤬
- WebRTC 에서 가장 많이 사용되고 있는 webm 포맷을 safari 에서는 오디오 형식 밖에 지원하지 않는다는 것도 걸림돌이다.
- webRTC 개발자가 제공하는 [RecordRTC](https://github.com/muaz-khan/WebRTC-Experiment/tree/master/RecordRTC) 라이브러리에서도 safari 11 은 음성레코딩만 지원한다.
- 데모에서 사용한 라이브러리를 대상으로 테스트 해봤을때 아래와 같은 제약조건 하에서 사용할 수 있따.
    1) gif.js 나 ccapture.js 를 사용하여 gif 포맷의 이미지로 사용하는 경우
    2) ffmpegserver.js 서버를 통해 mp4 로 인코딩 하는 경우
    3) canvas.toDataUrl 로 단일 스크린샷 이미지만 사용할 경우 


### safari 와 color filter
<img width="500" alt="2018-12-03 7 24 35" src="https://media.oss.navercorp.com/user/237/files/213011ee-f731-11e8-84c4-5ae5b94635af">

- 위 표에서 볼 수 잇듯이 `CanvasRenderingContext2D.filter` API 는 desktop / mobile 모든 버전에서 지원하지 않는다 [원본](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/filter#Browser_compatibility)
- 애플 공식 canvas 가이드에서는 image processing 을 위해서는 pixel 단위로 조작하는 것으로 [가이드](https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/HTML-canvas-guide/PixelManipulation/PixelManipulation.html#//apple_ref/doc/uid/TP40010542-CH16-SW4) 되고 있다. (2013 년도가 가장 최신 가이드..*) 
- [camanjs](http://camanjs.com) 와 같은 canvas manipulation library 를 이용하게 되면 모든 픽셀을 조작하는 비용이 매우 크기 때문에 실시간으로 프레임 업데이트가 필요한 동영상에는 적절하지 않다.
- **따라서 webgl과 shader 를 이용해서 라이브러리 혹은 직접 구현하는 방법을 추천한다.**
- webgl은 version1 을 기준으로 iOS8 부터 사용 가능하다.

#### 참고) 데모에서 사용한 glslCanvas 라이브러리 비교
- glslCanvas : WebGL을 사용해서 GLSL 쉐이더를 로드하는 라이브러리
- glfxjs : WebGL 이미지 효과 라이브러리
- glslCanvas 는 컬러 필터에 필요한 쉐이터 코드를 외부에서 입력 받고, glfxjs 는 필터에 필요한 쉐이더 코드 (ex. [sepia.js](https://github.com/evanw/glfx.js/blob/master/src/filters/adjust/sepia.js)) 를 내장하고 있다.
- glslCanvas 에서 제공하는 setUniform 함수에 대한 비용이 매우 크기 때문에 requestAnimationFrame 을 함께 사용하게 되면
    - 크롬에서는 `[Violation] 'requestAnimationFrame' handler took <N>ms` warning 
    - 사파리에서는 이전 프레임이 완료되기 전에 다음 프레임이 진행되어 화면이 멈추는 현상 (이전 프레임에 대한 페인팅이 취소됨) 또는 심하게 부자연스러운 화면이 나타난다.
    - 원인? (아마도..?) setUniform 을 사용하기 위해서는 canvas 의 toDataUrl API 를 매번 호출해야 하고 mousemove 이벤트가 발생할때마다 sandbox 를 resize 하는 requestAnimationFrame 을 내부에서 호출하고 있다.
- glfxjs 는 dataURL 조작 없이 canvas 에 직접 webgl API 를 사용해서 더 성능이 좋은..?것일까..?흑흑 잘 모르겠다
- 결론 : webgl 라이브러리도 잘 골라서 사용하도록 하자


#### 참고
- https://bloggeek.me/webrtc-ios-support/
- https://webkit.org/blog/7726/announcing-webrtc-and-media-capture/
- https://webkit.org/blog/7627/safari-technology-preview-32/
- https://developer.mozilla.org/ko/docs/Web/API/WebGL_API/Tutorial/Using_shaders_to_apply_color_in_WebGL
- https://addpipe.com/blog/html5-video-recording-webrtc-mediarecorder-api/
- https://webrtchacks.com/safari-webrtc/